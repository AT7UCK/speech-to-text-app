<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>STARM Industries STT</title>
  <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@500;700&display=swap" rel="stylesheet" />
  <script src="https://cdn.tailwindcss.com"></script>
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    body {
      font-family: 'Orbitron', sans-serif;
      background: radial-gradient(circle at top left, #010a13, #000);
      color: #0ff;
      transition: background 0.5s ease, color 0.5s ease;
      overflow-x: hidden;
    }

    body.light-mode {
      background: #f0f0f0;
      color: #000;
    }

    .holo-logo {
      position: absolute;
      top: 20px;
      left: 30px;
      font-size: 1.2rem;
      font-weight: 700;
      color: #00f5d4;
      text-shadow: 0 0 10px #00f5d4;
      animation: flicker 2s infinite alternate;
      z-index: 99;
    }

    .background-holo {
      position: absolute;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%) rotate(-30deg);
      font-size: 12rem;
      font-weight: 900;
      color: #00f5d4;
      opacity: 0.03;
      text-shadow: 0 0 40px #00f5d4;
      animation: flicker 4s infinite alternate;
      user-select: none;
      pointer-events: none;
    }

    .mic-pulse {
      width: 30px;
      height: 30px;
      border-radius: 50%;
      background: #0ff;
      box-shadow: 0 0 20px #0ff;
      margin: 10px auto;
      animation: pulse 1.5s infinite;
    }

    .hidden { display: none; }

    @keyframes pulse {
      0% { transform: scale(1); opacity: 1; }
      50% { transform: scale(1.2); opacity: 0.6; }
      100% { transform: scale(1); opacity: 1; }
    }

    @keyframes flicker {
      0%, 100% { opacity: 0.02; }
      50% { opacity: 0.06; }
    }

    canvas {
      background: rgba(0, 255, 255, 0.05);
      border-radius: 0.5rem;
    }
  </style>
</head>
<body>
  <div class="holo-logo">STARM INDUSTRIES</div>
  <div class="background-holo">STARM</div>

  <!-- Theme Toggle Button -->
  <div class="absolute top-5 right-5">
    <button onclick="toggleTheme()" class="bg-[#0ff] text-black px-4 py-2 rounded-lg shadow hover:bg-[#00d4c0]">
      Toggle Theme
    </button>
  </div>

  <!-- Mic Pulse -->
  <div class="mic-pulse hidden" id="micPulse"></div>

  <!-- Main Container -->
  <div class="max-w-2xl mx-auto mt-40 bg-white/10 p-8 rounded-2xl shadow-2xl backdrop-blur-md border border-cyan-500">
    <h1 class="text-center text-3xl mb-4 text-cyan-300">ðŸŽ¤ Speech-to-Text Converter</h1>

    <!-- Language Selector -->
    <select id="language_select" class="w-full p-3 rounded bg-black text-cyan-300 shadow">
      <option value="hi-IN">Hindi (India)</option>
      <option value="en-IN">English (India)</option>
      <option value="en-US" selected>English (US)</option>
      <option value="en-GB">English (UK)</option>
      <option value="pa-IN">Punjabi</option>
      <option value="ta-IN">Tamil</option>
      <option value="te-IN">Telugu</option>
    </select>

    <!-- Text Output -->
    <textarea id="convert_text" class="w-full h-40 mt-4 p-4 rounded bg-black text-cyan-300 shadow resize-none" placeholder="Transcribed text will appear here..."></textarea>

    <!-- Start/Stop Button -->
    <button id="click_to_record" class="mt-4 w-full py-3 bg-cyan-400 text-black font-bold rounded-lg shadow-lg hover:bg-cyan-300">
      ðŸŽ™ Start Recording
    </button>

    <!-- Status & Confidence -->
    <p id="is_recording" class="text-center text-sm mt-2">Status: Not Recording</p>
    <p id="confidence_id" class="text-center text-xs mt-1 text-gray-400"></p>

    <!-- Audio Visualizer -->
    <canvas id="audioCanvas" class="w-full h-16 mt-6"></canvas>
  </div>

  <!-- JavaScript Logic -->
  <script>
    let isRecording = false;
    let manuallyStopped = false;
    let recognition;
    let audioContext, analyser, dataArray, source;

    const button = document.getElementById("click_to_record");
    const content = document.getElementById("convert_text");
    const status = document.getElementById("is_recording");
    const confidenceDisplay = document.getElementById("confidence_id");
    const languageSelector = document.getElementById("language_select");
    const canvas = document.getElementById("audioCanvas");
    const ctx = canvas.getContext("2d");
    const micPulse = document.getElementById("micPulse");

    function drawWaveform() {
      if (!analyser) return;
      requestAnimationFrame(drawWaveform);
      analyser.getByteTimeDomainData(dataArray);
      ctx.fillStyle = "rgba(0, 0, 0, 0.2)";
      ctx.fillRect(0, 0, canvas.width, canvas.height);
      ctx.lineWidth = 2;
      ctx.strokeStyle = "#0ff";
      ctx.beginPath();
      const sliceWidth = canvas.width / dataArray.length;
      let x = 0;
      for (let i = 0; i < dataArray.length; i++) {
        let v = dataArray[i] / 128.0;
        let y = (v * canvas.height) / 2;
        i === 0 ? ctx.moveTo(x, y) : ctx.lineTo(x, y);
        x += sliceWidth;
      }
      ctx.lineTo(canvas.width, canvas.height / 2);
      ctx.stroke();
    }

    async function setupAudioVisualization() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        analyser = audioContext.createAnalyser();
        source = audioContext.createMediaStreamSource(stream);
        source.connect(analyser);
        analyser.fftSize = 2048;
        dataArray = new Uint8Array(analyser.frequencyBinCount);
        drawWaveform();
      } catch (err) {
        console.error("Mic access error:", err);
      }
    }

    function toggleTheme() {
      document.body.classList.toggle("light-mode");
    }

    try {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      if (!SpeechRecognition) throw new Error("Speech Recognition not supported");

      recognition = new SpeechRecognition();
      recognition.continuous = true;
      recognition.interimResults = true;

      recognition.onresult = (event) => {
        let finalTranscript = "", interimTranscript = "";
        for (let i = event.resultIndex; i < event.results.length; i++) {
          const transcript = event.results[i][0].transcript;
          event.results[i].isFinal ? finalTranscript += transcript : interimTranscript += transcript;
        }
        content.value = finalTranscript + interimTranscript;
        const confidence = event.results[event.results.length - 1][0].confidence;
        if (confidence) confidenceDisplay.textContent = `Confidence: ${(confidence * 100).toFixed(2)}%`;
      };

      recognition.onerror = (e) => {
        status.textContent = `Error: ${e.error}`;
        isRecording = false;
        button.textContent = "ðŸŽ™ Start Recording";
        micPulse.classList.add("hidden");
      };

      recognition.onend = () => {
        status.textContent = "Status: Not Recording";
        micPulse.classList.add("hidden");
        if (isRecording && !manuallyStopped) recognition.start(); // Auto-restart
      };

      button.addEventListener("click", async () => {
        if (!isRecording) {
          await setupAudioVisualization();
          recognition.lang = languageSelector.value;
          recognition.start();
          isRecording = true;
          manuallyStopped = false;
          micPulse.classList.remove("hidden");
          status.textContent = "Status: Recording...";
          button.textContent = "ðŸ›‘ Stop Recording";
        } else {
          recognition.stop();
          manuallyStopped = true;
          isRecording = false;
          micPulse.classList.add("hidden");
          status.textContent = "Status: Not Recording";
          button.textContent = "ðŸŽ™ Start Recording";
        }
      });
    } catch (err) {
      alert("Speech Recognition not supported in this browser.");
      console.error(err);
    }
  </script>
</body>
</html>
